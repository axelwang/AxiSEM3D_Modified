{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23585f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import pyvtk\n",
    "import re\n",
    "from toolz import first\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "import pickle\n",
    "\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, fire_and_forget, futures_of, wait\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "from dask import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55774538",
   "metadata": {},
   "source": [
    "## Set up dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2620b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 25\n",
    "num_mem = num_cores*8\n",
    "run_time = \"06:00:00\"\n",
    "extra_args = [\"--output= WHERE DO YOU WANT SLURM OUTPUT TO GO\"]\n",
    "cluster = SLURMCluster(cores=num_cores,memory=str(num_mem)+\"GB\",processes=1,walltime= run_time, \n",
    "                       job_extra_directives=extra_args)\n",
    "# disable worker heartbeat\n",
    "cfg.set({'distributed.scheduler.worker-ttl': None})\n",
    "# extend some time limits\n",
    "cfg.set({'distributed.comm.timeouts.connect': 300})\n",
    "cfg.set({'distributed.comm.timeouts.tcp': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "194c412d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = 20\n",
    "cluster.scale(num_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10c769e",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1725149",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(num_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfb8c5",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb614bf",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86311fe",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dir (location for filtered data)\n",
    "data_dir = \"\"\n",
    "\n",
    "# Where to save files:\n",
    "dest_dir = \"\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d876d2af",
   "metadata": {},
   "source": [
    "## Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e895594",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_channel = 'T'     # Channel of the wavefield: RTZ \n",
    "phi = 45                # Azimuth of the physical slice in degrees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8bc4b",
   "metadata": {},
   "source": [
    "## Time step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe17438a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = 0.1                 # sampling frequency used for output in simulation\n",
    "frame_rate = 0.5         # every how many second to save a frame "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fe3c29",
   "metadata": {},
   "source": [
    "### Undulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10834481",
   "metadata": {},
   "outputs": [],
   "source": [
    "undulated = True\n",
    "#### Directory containing files to compute dZ \n",
    "fileDir =''\n",
    "### Undulation geometry file name:\n",
    "undFile = 'dz_dict.pkl'\n",
    "### Set Nr as used in simulation\n",
    "Nr = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75d8fd",
   "metadata": {},
   "source": [
    "## Element points selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb004e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose:\n",
    "# \"center\"\n",
    "# \"ccm\" (center, corner, midpoints)\n",
    "element_points = \"center\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b8b3f",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25ba27",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6131dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_fnames = [f for f in os.listdir(data_dir) if 'filtered' in f]\n",
    "for k in range(len(nc_fnames)):\n",
    "    nc_fnames[k] = data_dir + '/' + nc_fnames[k]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2b22c1",
   "metadata": {},
   "source": [
    "### List of distributed or serial tasks for loading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aac3b3e",
   "metadata": {},
   "source": [
    "#### parallelize over number of nc data sets, i.e. MPI ranks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d35e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_datasets(nc_fname):\n",
    "    # open a dataset \n",
    "    \n",
    "    return xr.open_dataset(nc_fname,engine=\"netcdf4\",chunks={}) # This converts all arrays inside to Dask arrays\n",
    "\n",
    "def load_coords(nc_file):\n",
    "    '''\n",
    "    Load coordinates sz from each NC file.\n",
    "    Directly acccess the 'variables' below, which returns\n",
    "    dask arrays.\n",
    "    '''\n",
    "    # read coordinates\n",
    "\n",
    "    return nc_file.variables['sz']\n",
    "\n",
    "def load_elem_tag(nc_file):   \n",
    "    return nc_file.variables['tags']\n",
    "\n",
    "def load_fdata(nc_file):\n",
    "    '''\n",
    "    Load filtered data\n",
    "    '''\n",
    "\n",
    "    return nc_file.variables['filtered_data']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b211c6cc",
   "metadata": {},
   "source": [
    "\n",
    "### submit tasks for loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2702b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "nc_file_futures = client.map(open_datasets,nc_fnames)\n",
    "\n",
    "load_coords_futures = client.map(load_coords,nc_file_futures)\n",
    "all_coords_sz = da.concatenate(client.gather(load_coords_futures),axis=0)\n",
    "\n",
    "elem_tag_futures = client.map(load_elem_tag,nc_file_futures)\n",
    "elem_tag_all = da.concatenate(client.gather(elem_tag_futures),axis=0)\n",
    "\n",
    "load_fdata_futures = client.map(load_fdata,nc_file_futures)\n",
    "fdata = da.concatenate(client.gather(load_fdata_futures),axis=0)\n",
    "\n",
    "nelem = len(elem_tag_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab22e94",
   "metadata": {},
   "source": [
    "## Generate wavefield animation on a physical slice\n",
    "\n",
    "### Note: several parameters to tune below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c3bab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GLL layout in one element:\n",
    "# 4 - 9 - 14 - 19 - 24\n",
    "# |   |    |    |    |\n",
    "# 3 - 8 - 13 - 18 - 23\n",
    "# |   |    |    |    |\n",
    "# 2 - 7 - 12 - 17 - 22\n",
    "# |   |    |    |    | \n",
    "# 1 - 6 - 11 - 16 - 21\n",
    "# |   |    |    |    |\n",
    "# 0 - 5 - 10 - 15 - 20\n",
    "\n",
    "# Spatial downsampling:\n",
    "# corners+center+midpoint:\n",
    "# 2--5--8\n",
    "# |  |  |\n",
    "# 1--4--7\n",
    "# |  |  |\n",
    "# 0--3--6\n",
    "# This corresponds to \n",
    "# 4-14-24\n",
    "# |  |  |\n",
    "# 2-12-22\n",
    "# |  |  |\n",
    "# 0-10-20\n",
    "# in the dZ array\n",
    "\n",
    "# Connectivity array (shared by all slices and time frames)\n",
    "connectivity = []\n",
    "\n",
    "# Undulating index:\n",
    "if element_points == \"ccm\":\n",
    "    # corners+midpoints+center\n",
    "    undIdx = [0,2,4,10,12,14,20,22,24]\n",
    "    \n",
    "    for ielem in np.arange(nelem):\n",
    "        start = ielem * 9\n",
    "        connectivity.append([start + 0, start + 1, start + 4, start + 3])\n",
    "        connectivity.append([start + 1, start + 2, start + 5, start + 4])\n",
    "        connectivity.append([start + 3, start + 4, start + 7, start + 6])\n",
    "        connectivity.append([start + 4, start + 5, start + 8, start + 7])\n",
    "    \n",
    "elif element_points == \"center\":\n",
    "    # center only\n",
    "    undIdx = [12]\n",
    "    ngll=len(undIdx)\n",
    "    for ielem in np.arange(nelem):\n",
    "        start = ielem * ngll\n",
    "        connectivity.append([start + 0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87342283",
   "metadata": {},
   "source": [
    "### Function to convert coordinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651b0372",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sz2rtheta(s,z):\n",
    "    '''\n",
    "    Convert cylindrical s,z to spherical r, theta\n",
    "    '''\n",
    "    r = np.sqrt(s**2+z**2)\n",
    "    theta = np.arccos(z/r)\n",
    "    return r,theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc29dae",
   "metadata": {},
   "source": [
    "### Get wave on the particular physical slice and channel\n",
    "### Get coordinates for the physical slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302f95c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_coords_sz = all_coords_sz.compute()\n",
    "elem_tag_all = elem_tag_all.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357b8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "### Undulated geometry \n",
    "if undulated:\n",
    "    with open(fileDir+undFile,\"rb\") as p:\n",
    "        dict_data_dz = pickle.load(p)\n",
    "    if element_points == \"center\":\n",
    "        pts_per_elem = ngll\n",
    "    elif element_points == \"ccm\":\n",
    "        pts_per_elem = 9    \n",
    "    for ielem in np.arange(nelem):\n",
    "        elemTag = int(elem_tag_all[ielem])\n",
    "        start = ielem * pts_per_elem\n",
    "        if elemTag in dict_data_dz.keys():\n",
    "            dz = dict_data_dz[elemTag]\n",
    "            r,theta = sz2rtheta(all_coords_sz[start:(start+ngll), 0],all_coords_sz[start:(start+ngll), 1])\n",
    "            # S\n",
    "            all_coords_sz[start:(start+ngll), 0] += dz[undIdx]*np.sin(theta)\n",
    "            # Z\n",
    "            all_coords_sz[start:(start+ngll), 1] += dz[undIdx]*np.cos(theta)\n",
    "            \n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1903e9f5",
   "metadata": {},
   "source": [
    "## Final preperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7749ab35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lscratch_dir = os.getenv('L_SCRATCH_JOB')\n",
    "def make_and_save_vtk(tlist,**kwargs):\n",
    "    ### MPI rank\n",
    "    rank = str(kwargs[\"rank\"])\n",
    "    save_dir = lscratch_dir + '/task' +rank\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    ### vtk mesh\n",
    "    x = kwargs[\"coords\"][:, 0] * np.cos(phi)\n",
    "    y = kwargs[\"coords\"][:, 0] * np.sin(phi)\n",
    "    z = kwargs[\"coords\"][:, 1]\n",
    "    vtk_mesh = pyvtk.UnstructuredGrid(list(zip(x, y, z)),\n",
    "                                      vertex=kwargs[\"connect\"])\n",
    "\n",
    "    for itime in tlist:\n",
    "        vtk = pyvtk.VtkData(vtk_mesh, pyvtk.PointData(pyvtk.Scalars(fdata[:,itime].compute(), name='U' + wave_channel)))\n",
    "        saveFile = save_dir +\"/fwave%d.vtk\" % itime\n",
    "        destFile = dest_dir + \"/fwave%d.vtk\" % itime\n",
    "        vtk.tofile(saveFile, 'binary')\n",
    "        shutil.copyfile(saveFile, destFile)\n",
    "    return \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a03f6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_future = client.scatter(all_coords_sz,broadcast=True)\n",
    "con = np.asarray(connectivity)\n",
    "connect_future = client.scatter(con,broadcast=True)\n",
    "\n",
    "phi = np.radians(phi)\n",
    "\n",
    "ntime = fdata.shape[1]\n",
    "time_gap = int(frame_rate/dt)\n",
    "time_list = np.arange(0,ntime,time_gap)\n",
    "time_bag = db.from_sequence(time_list,npartitions=100)\n",
    "time_bag = time_bag.persist()\n",
    "wait(time_bag)\n",
    "\n",
    "# Write out a text file for the number of outputs to expect\n",
    "with open(dest_dir+'/NOF.txt','w') as f:\n",
    "    f.write(\"The number of expected filtered VTK files is: %d\" % len(time_list)+'\\n')\n",
    "\n",
    "# Find out which worker has which piece of data, hence MPI rank assigned by Dask\n",
    "key_to_part_dict = {str(part.key): part for part in futures_of(time_bag)}\n",
    "who_has = client.who_has(time_bag)\n",
    "worker_map = defaultdict(list)\n",
    "for key, workers in who_has.items():\n",
    "    worker_map[first(workers)].append(key_to_part_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e95ada8",
   "metadata": {},
   "source": [
    "# Submit tasks to write vtk files!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfba652d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for worker, list_of_parts in worker_map.items():\n",
    "    for i in range(len(list_of_parts)):\n",
    "        f.append(client.submit(make_and_save_vtk,list_of_parts[i],rank = list_of_parts[i].key[1],\n",
    "                               coords=coord_future,connect=connect_future,\n",
    "                               workers=worker))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fba5b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
