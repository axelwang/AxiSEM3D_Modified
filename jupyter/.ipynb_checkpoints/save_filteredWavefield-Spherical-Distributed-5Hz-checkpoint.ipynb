{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23585f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "from toolz import first\n",
    "from collections import defaultdict\n",
    "import shutil\n",
    "from scipy import signal\n",
    "\n",
    "import dask\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client, fire_and_forget, futures_of, wait\n",
    "import dask.array as da\n",
    "import dask.bag as db\n",
    "from dask import config as cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cfb8c5",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb614bf",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d86311fe",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa3886",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data dir\n",
    "data_dir = \"\"\n",
    "\n",
    "# Where to save files:\n",
    "dest_dir = \"\"\n",
    "os.makedirs(dest_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768573bc",
   "metadata": {},
   "source": [
    "### Data selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f743fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_channel = 'T'     # Channel of the wavefield: RTZ \n",
    "\n",
    "# wave channel to select\n",
    "wave_dim = 'RTZ'.index(wave_channel)   # finds the index for wave_channel in string \"RTZ\"\n",
    "# NaG\n",
    "nag = 1\n",
    "# Slice number\n",
    "islice = 0 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8b8b3f",
   "metadata": {},
   "source": [
    "---------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf25ba27",
   "metadata": {},
   "source": [
    "## Look for data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5debde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All original file names\n",
    "nc_fnames = [f for f in os.listdir(data_dir) if 'axisem3d_synthetics.nc' in f]\n",
    "\n",
    "# Find rank numbers that have already been done\n",
    "present_ranks = []\n",
    "for f in os.listdir(dest_dir):\n",
    "    present_ranks.append(f.split('.')[-1])\n",
    "\n",
    "done_fnames = ['axisem3d_synthetics.nc'+'.'+x for x in present_ranks]\n",
    "todo_fnames = list(set(nc_fnames)-set(done_fnames))\n",
    "\n",
    "# First run, only aim to do 300 of these\n",
    "#todo_fnames = todo_fnames[0:300]\n",
    "\n",
    "for k in range(len(todo_fnames)):\n",
    "    todo_fnames[k] = data_dir + '/' + todo_fnames[k]\n",
    "\n",
    "print(\"%d NC files to consider\" % len(todo_fnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc29c410",
   "metadata": {},
   "source": [
    "## Set up dask cluster\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d7c40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 25\n",
    "num_mem = num_cores*8\n",
    "run_time = \"9:00:00\"\n",
    "extra_args = [\"--output=SLURM OUTPUT DIRECTORY\"]\n",
    "cluster = SLURMCluster(cores=num_cores,memory=str(num_mem)+\"GB\",processes=1,walltime= run_time, \n",
    "                       job_extra_directives=extra_args)\n",
    "# disable worker heartbeat\n",
    "cfg.set({'distributed.scheduler.worker-ttl': None})\n",
    "# extend some time limits\n",
    "cfg.set({'distributed.comm.timeouts.connect': 300})\n",
    "cfg.set({'distributed.comm.timeouts.tcp': 300})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2266e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_nodes = int(np.ceil(len(todo_fnames)/num_cores))\n",
    "#num_nodes = 5\n",
    "print(\"%d nodes requested\" % num_nodes)\n",
    "cluster.scale(num_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb51a7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(cluster)\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client.wait_for_workers(num_nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6413d4",
   "metadata": {},
   "source": [
    "## Make and distribute the filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3777f9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make filter with Scipy\n",
    "low_corner = 1\n",
    "high_corner = 4.99\n",
    "filter_order = 8\n",
    "sampling_frequency = 1/0.1  # check this in the element-wise section of inparam.output.yaml!!!\n",
    "butter_filter = signal.butter(filter_order,[low_corner, high_corner],'bandpass',output='sos',fs=sampling_frequency)\n",
    "filter_futures = client.scatter(butter_filter,broadcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00ebe02",
   "metadata": {},
   "source": [
    "## Distribute data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d35e12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_datasets(nc_fname):\n",
    "    # open a dataset\n",
    "    nc_file = xr.open_dataset(nc_fname,engine=\"netcdf4\",chunks={})  # This converts all arrays inside to Dask arrays\n",
    "    \n",
    "    return [nc_file, nc_fname]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35dace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_bag = db.from_sequence(todo_fnames, npartitions=len(todo_fnames)).map(open_datasets)\n",
    "data_bag = data_bag.persist()\n",
    "wait(data_bag)\n",
    "\n",
    "# Find out which worker has which piece of data, hence MPI rank assigned by Dask\n",
    "key_to_part_dict = {str(part.key): part for part in futures_of(data_bag)}\n",
    "who_has = client.who_has(data_bag)\n",
    "worker_map = defaultdict(list)\n",
    "for key, workers in who_has.items():\n",
    "    worker_map[first(workers)].append(key_to_part_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b160b569",
   "metadata": {},
   "source": [
    "## Save filtered data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5945364e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lscratch_dir = os.getenv('L_SCRATCH_JOB')\n",
    "def save_filtered_wavefield(butter_filter,data,**kwargs):\n",
    "    ### MPI rank for this job\n",
    "    rank = kwargs[\"rank\"]\n",
    "    save_dir = lscratch_dir + '/task' +str(rank)\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "       \n",
    "    ### Load and select data\n",
    "    # Select the GLL coordinate in each element to filter\n",
    "    elemGLL = 4\n",
    "    wave_component = data[0][0].variables['data_wave__NaG=1'][:,kwargs[\"nslice\"],elemGLL,kwargs[\"channel\"],:].data\n",
    "    #wave_space_time = wave_component.data\n",
    "    \n",
    "    szInFile = data[0][0].variables['list_element_coords'][:,elemGLL,:].data\n",
    "    \n",
    "    elemTag = data[0][0].variables['list_element_na'][:,0].data\n",
    "    \n",
    "    ### MPI rank for the original file\n",
    "    original_rank = data[0][1].split('/')[-1].split('.')[-1]\n",
    "    \n",
    "    ### Prepare to save filtered data\n",
    "    # Name the files with original rank\n",
    "    saveFile = save_dir +\"/filtered.nc\" +'.'+original_rank\n",
    "    destFile = dest_dir + \"/filtered.nc\" +'.'+original_rank\n",
    "    try: ncfile.close()  # just to be safe, make sure dataset is not already open. \n",
    "    except: pass         # Be careful, opening a file with 'w' will clobber any existing data\n",
    "    ncfile = nc.Dataset(saveFile,mode='w',format='NETCDF4')\n",
    "    # Dimensions\n",
    "    time_dim = ncfile.createDimension('time', None)       # time axis, unlimited\n",
    "    coord_dim = ncfile.createDimension('coord', 2)        # coord axis, dim 2 for s, z\n",
    "    nelem_dim = ncfile.createDimension('nelem', szInFile.shape[0])       # element axis, dim numer of elements in this file\n",
    "    # Variables\n",
    "    filtered_data = ncfile.createVariable('filtered_data', np.float32, ('nelem','time')) \n",
    "    coordInFile = ncfile.createVariable('sz',np.float32,('nelem','coord'))\n",
    "    elemTagInFile = ncfile.createVariable('tags',np.uint,('nelem'))\n",
    "    \n",
    "    # Put in coordinates\n",
    "    coordInFile[:,:] = szInFile\n",
    "    # Put in global element tag numbers\n",
    "    elemTagInFile[:] = elemTag\n",
    "    \n",
    "    ### Filter and save\n",
    "    for ielem in range(wave_component.shape[0]):\n",
    "        filtered_data[ielem,:] = signal.sosfilt(butter_filter,wave_component[ielem,:].astype(\"float32\"))\n",
    "\n",
    "    ### Close and copy back the file\n",
    "    ncfile.close()\n",
    "    shutil.copyfile(saveFile, destFile)\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = []\n",
    "for worker, list_of_parts in worker_map.items():\n",
    "    for i in range(len(list_of_parts)):\n",
    "        f.append(client.submit(save_filtered_wavefield,filter_futures,list_of_parts[i],\n",
    "                               rank=list_of_parts[i].key[1], nslice=islice, channel=wave_dim,\n",
    "                               workers=worker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0dece42",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
